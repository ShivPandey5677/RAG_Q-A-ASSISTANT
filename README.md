# ğŸ§  RAG-Powered Multi-Agent Q&A Assistant

This project is a multi-agent knowledge assistant that combines **retrieval-augmented generation (RAG)** with simple **tool-based routing** (calculator and dictionary). It is implemented in two variants:

- âœ… **Version 1: Offline/Free** â€“ No OpenAI key required
- âœ… **Version 2: Online/OpenAI-Powered** â€“ Uses GPT-3.5 with Chroma for better answers

---

## ğŸ—ï¸ Architecture Overview

| Component       | Offline Version                                | Online Version             |
| --------------- | ---------------------------------------------- | -------------------------- |
| Embeddings      | `HuggingFaceEmbeddings`                        | `OpenAIEmbeddings`         |
| Vector Store    | `FAISS`                                        | `Chroma`                   |
| LLM Response    | Mock response                                  | `gpt-3.5-turbo` via OpenAI |
| Dictionary Tool | [dictionaryapi.dev](https://dictionaryapi.dev) | Same                       |
| Calculator Tool | [api.mathjs.org](https://api.mathjs.org)       | Same                       |

---

## ğŸ§  Agent Workflow Logic

1. **If query includes `define`** â†’ Use dictionary tool
2. **If query includes `calculate`** â†’ Use calculator tool
3. **Otherwise** â†’ Run RAG Pipeline:
   - Embed the query
   - Retrieve top 3 relevant text chunks
   - Generate a natural language answer (mock or LLM)

---

## ğŸ“ File Structure

â”œâ”€â”€app1.py # Hugging Face Streamlit app (version 1 )
â”œâ”€â”€app2.py # Open AI Streamlit app (version 2)
â”œâ”€â”€ docs/ # Folder containing .txt source documents
â”œâ”€â”€ .env # API keys
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file

---

## ğŸš€ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

Create a .env that includes
OPENAI_API_KEY=your_openai_key
LANGCHAIN_API_KEY=your_langchain_key

## 4 Start the App

streamlit run app.py

![alt text](image.png)
![alt text](image-1.png)
